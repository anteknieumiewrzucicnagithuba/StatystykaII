---
title: "Predykcja umieralności na nowotwór Glioblastoma"
author: "Ewelina Karbowiak i Wioleta Stojak"
output:
    html_document:
         toc: true
         toc_float:
          collapsed: false
          smooth_scroll: false
---
**Abstract** Celem projektu jest zbudowanie algorytmu, który na podstawie danych o pacjentach ze zdiagnozowanym nowotworem Glioblastoma będzie mógł możliwie dokładnie oszacować czy pacjent przeżyje 1 rok od diagnozy.

#Dane
Dostępne dane zawierały informacje o pacjentach w zależności od wieku, podtypu nowotworu, stanu pacjenta po pierwszym roku od diagnozy oraz wartości ekspresji 16115 genów.

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(ggplot2)
library("e1071")
library(party)
library(rpart)
library(rpart.plot)
library(hydroGOF)
library(vioplot)
library(caret)
library(knitr)
library(SDMTools)
library(ROCR)
library(ipred)
library(xtable)
library(MASS)
library("reshape2")
library(klaR)
library("pROC")
library("randomForest")
library(xgboost)
library(clusterSim)
library("caretEnsemble")

library(ModelMetrics)
```

#Przygotowanie danych
Na początek pacjenci zostali podzieleni na dwie grupy. W pierwszej znaleźli się ci, którzy przeżyli pierwszy rok po postawionej diagnozie, natomiast do drugiej grupy zostali przydzieleni pozostali uczestnicy badania, którzy nie przeżyli pierwszego roku od diagnozy. W dostępnych danych usunęłyśmy te kolumny, które zawierały więcej niż 8 NA w obrębie swojej grupy i dodaliśmy dodatkową kolumnę zero-jedynkową o nazwie **smierc**, w której 1 jest przypisywana, gdy pacjent przeżył rok od diagnozy, a 0 w przeciwnym przypadku. Pozostałe wartości NA w dalszej części projektu są uzupełniane przez średnią z kolumny, w której się znajdują.

```{r}
 load("C:/Users/ws345465/Downloads/LASSOCV now.rda")
 load("C:/Users/ws345465/Downloads/GBMCVnowy.rda")
 load("C:/Users/ws345465/Downloads/GlioblastomaWide .rda")
 load("C:/Users/ws345465/Downloads/GLMCVnow.rda")
 load("C:/Users/ws345465/Downloads/LASSOCV now.rda")
 load("C:/Users/ws345465/Downloads/MSECVtree now.rda")
 load("C:/Users/ws345465/Downloads/NBCVnow.rda")
 load("C:/Users/ws345465/Downloads/OPICGLMCVnow.rda")
 load("C:/Users/ws345465/Downloads/RFCVnow.rda")
 load("C:/Users/ws345465/Downloads/RIDGECV now.rda")
 load("C:/Users/ws345465/Downloads/SVMCV now.rda")
geny<-GlioblastomaWide
z<-geny
ILOSCNAa<-(colSums(is.na(z[z$death1y=='alive',]))> 8)
ILOSCNAd<-(colSums(is.na(z[z$death1y=='dead',]))>8)
maska<- (ILOSCNAd | ILOSCNAa)
z<-z[,!maska]
geny<-z
geny$smierc<-ifelse(geny$death1y=="alive",1,0)
```


#Identyfikacja istotnych genów
Do uzyskania informacji o genach i ich istotności posłużyłyśmy się testem t studenta oraz zastosowałyśmy **metodę fdr** do estymacji otrzymanych p-value. 
Ostatecznie wybrałyśmy 30 istotnych genów z najmniejszą p-wartością.

```{r message=FALSE, warning=FALSE}
istotne<-function(z,s){  
pvalue<-NULL
dead2<-z[z$death1y == "dead",]
alive2<-z[z$death1y == "alive",]
  
for (i in 5:ncol(z)){
  x<-dead2[,i]
  y<-alive2[,i]
  pvalue[i]<- t.test(x,y,alternative = "two.sided")$p.value
}
pvalue_poprawka<-p.adjust(pvalue, method = "fdr")
posortowane<-order(pvalue_poprawka,decreasing = FALSE)
ist<-posortowane[1:s]
colnames(z[,ist])
}
```

#Zbadane modele

Aby wybrać model najlepiej stosujący się do naszych danych, przetestowane zostały różne podejścia, zarówno liniowe jak i nieliniowe.

Użyte modele :

*uogólniony model liniowy glm

*powyższy model z wykorzystaniem kryterium BIC

*Lasso  

*drzewo decyzyjne z wykorzystaniem funkcji rpart

*SVM

*Naive Bayes

*las losowy

*gradient boosting

Aby wybrać najlepszy model  ograniczyłyśmy się do badania błędu średniokwadratowego (MSE) przez 10-fold CV z powtórzeniem 10 krotnym oraz porównania średniego pola pod wykresami krzywych ROC. Istotne geny były wybieranie ze zbioru treningowego, podczas każdej cross walidacji.
Poniżej zamieszczamy przykładową funkcją, którą do tego wykorzystałyśmy i przykładowe zastosowanie w CV. (Pozostałe zostały w raporcie ukryte).

```{r}

MSEAUCGLM<-function(geny,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],25)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    model_GLM<-glm(smierc~.,data=train[,-2],family = binomial(link="logit"),control =    list(maxit = 50))
    predy <-round(predict (model_GLM,newdata = test[,-2],type = "response"))
    c(mse(predy,test[,"smierc"]), roc(test[,"smierc"],predy)$auc)
}
```

```{r,message=FALSE, warning=FALSE,echo=FALSE}
MSEAUCBICGLM<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    model_GLM<-glm(smierc~.,data=train[,-2],family="binomial")
    optimalBICGLM<-step(model_GLM,direction = "backward",trace = FALSE,k=log(nrow(train)))
    predy.optimalBICGLM<-round(predict(optimalBICGLM,newdata=test[,-2],type="response"))
    c(mse(predy.optimalBICGLM,test[,"smierc"]),roc(test[,"smierc"],predy.optimalBICGLM)$auc)
}
MSEAUCTREE<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    model_RP<-rpart(smierc~.,data=train[,-2])
    predy_RP<-round(predict(model_RP,newdata = test[,-2]))
    c(mse(predy_RP,test[,"smierc"]), roc(test[,"smierc"],predy_RP)$auc)
}
MSEAUCNB<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    model_NB<-naiveBayes(as.factor(smierc)~.,data=train[,-2])
    predy_NB<-predict(model_NB,newdata=test[,-2])
    predi<-as.numeric(as.vector(predy_NB))
    c(mse(predi,test[,"smierc"]), roc(test[,"smierc"],predi)$auc)
}
MSEAUCRF<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    model_RF<-randomForest(as.factor(smierc)~.,data=train[,-2],ntree=25)
    predy_RF<-as.numeric(as.matrix(predict(model_RF,newdata = test[,-2])))
    c(mse(predy_RF,test[,"smierc"]), roc(predy_RF,test[,"smierc"])$auc)
}

MSEAUCGB<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
   modGBM <- gbm(smierc ~., data = train[,-2], distribution = "bernoulli")
   predGBM <-round(predict(modGBM, test[,-2], n.trees=100, type="response"))
    c(mse(predGBM,test[,"smierc"]),roc(test[,"smierc"],predGBM)$auc)
}
MSEAUCSVM<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    X<-as.matrix(train[,-2])
    Y<-as.matrix(test[,-2])
    model_SVM<-svm(smierc~.,data=X)
    predy_SVM<-round(predict(model_SVM,newdata = Y))
    c(mse(predy_SVM,test[,"smierc"]), roc(test[,"smierc"],predy_SVM)$auc)
}
MSEAUCLASSO<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    X<-as.matrix(train[,-c(2,ncol(train))])
    X<-scale(X)
    Y<-as.matrix(test[,-c(2,ncol(test))])
    Y<-scale(Y)
    modelLASSO<-cv.glmnet(x=X,y=train[,"smierc"],type.measure='mse', keep=TRUE,    alpha=1,family="binomial")
    lambda.lasso<-modelLASSO$lambda.min
    pred_LASSO = round(predict(modelLASSO, s = lambda.lasso, newx =Y,type="response") )
      c(mse(pred_LASSO,test[,"smierc"]),roc(pred_LASSO,test[,"smierc"])$auc)
}
MSEAUCRIDGE<-function(dane,ind){
    train<-geny[-ind,]
    test<-geny[ind,]
        for(i in 5:(ncol(train)-1)){
          train[which(is.na(train[,i])),i] <- mean(train[,i], na.rm = TRUE)
        }
    istotne<-istotne(train[-ind,-ncol(train)],30)
    train<-train[,c("age","death1y",istotne,"smierc")]
    test<-test[,c("age","death1y",istotne,"smierc")]
        for(j in 3:(ncol(test)-1)){
          test[which(is.na(test[,j])), j] <-mean(test[,j], na.rm = TRUE)
        }
    X<-as.matrix(train[,-c(2,ncol(train))])
    X<-scale(X)
    Y<-as.matrix(test[,-c(2,ncol(test))])
    Y<-scale(Y)
      
    modelRIDGE<-cv.glmnet(x=X,y=train[,"smierc"],type.measure='mse', keep=TRUE,    alpha=0,family="binomial")
    lambda.RIDGE<-modelRIDGE$lambda.min
    pred_RIDGE = round(predict(modelRIDGE, s = lambda.RIDGE, newx =Y,type="response") )
      c(mse(pred_RIDGE,test[,"smierc"]),roc(pred_RIDGE,test[,"smierc"])$auc)
}
```

Uogólniony model liniowy glm
```{r message=FALSE, warning=FALSE, eval = FALSE}
GLMCV<-replicate(10,{
    jak<-createFolds(geny$death1y,k=10)
    error<-lapply(jak,function(ind) {
    MSEAUCGLM(geny,ind)
        })
})

```

Optymalny model według kryterium BIC 

```{r,message=FALSE,warning=FALSE, eval = FALSE,echo=FALSE}

OPICGLMCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCBICGLM(geny,ind)
  })
})

LASSOCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCLASSO(geny,ind)
  })
})


RIDGECV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCRIDGE(geny,ind)
  })
})

MSECVtree <- replicate(3, {
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCTREE(geny,ind)  
  })
}
)


SVMCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCSVM(geny,ind)
  })
})



NBCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCNB(geny,ind)
  })
})


RFCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCRF(geny,ind)    
  })
})


GBMCV<-replicate(10,{
     jak<-createFolds(geny$death1y,k=10)
     error<-lapply(jak,function(ind) {
     MSEAUCGB(geny,ind)
  })

})

```

#Porównanie użytych metod

Poniżej przedstawiamy rozkład błędów średniokwadratowych oraz AUC dla powyższych modeli  dla 10-fold CV powtórzonej 10 razy.

Widzimy, że w przypadku błędu MSE jego rozkłady w modelach są podobne, jednak DRZEWO i GBM wyróżniają się tym, że błąd MSE jest zawsze większy od 0.2. 

Dla rozkładu AUC najlepiej wypadły metody  RF i LASSO, które charakteryzują się polem pod krzywą ROC stale większym od 0.5.


```{r,warning=FALSE,message=FALSE,echo=FALSE}
METODY<-c("glm_CV","glmbic_CV","DRZEWO_CV","NB_CV","RF_CV","GBM_CV","SVM_CV","LASSO_CV")
liczbamet<-numeric(8)

MSEcv<-liczbamet
names(MSEcv)<-METODY

MSEcv[1]<-mean(unlist(GLMCV)[seq(1,length(unlist(GLMCV)),2)])
MSEcv[2]<-mean(unlist(OPICGLMCV)[seq(1,length(unlist(OPICGLMCV)),2)])
MSEcv[3]<-mean(unlist(MSECVtree)[seq(1,length(unlist(MSECVtree)),2)])
MSEcv[4]<-mean(unlist(NBCV)[seq(1,length(unlist(NBCV)),2)])
MSEcv[5]<-mean(unlist(RFCV)[seq(1,length(unlist(RFCV)),2)])
MSEcv[6]<-mean(unlist(GBMCV)[seq(1,length(unlist(GBMCV)),2)])
MSEcv[7]<-mean(unlist(SVMCV)[seq(1,length(unlist(SVMCV)),2)])
MSEcv[8]<-mean(unlist(LASSOCV)[seq(1,length(unlist(LASSOCV)),2)])
#MSEcv[9]<-mean(unlist(RIDGECV)[seq(1,length(unlist(RIDGECV)),2)])

AUCcv<-liczbamet
names(AUCcv)<-METODY
AUCcv[1]<-mean(unlist(GLMCV)[seq(2,length(unlist(GLMCV)),2)])
AUCcv[2]<-mean(unlist(OPICGLMCV)[seq(2,length(unlist(OPICGLMCV)),2)])
AUCcv[3]<-mean(unlist(MSECVtree)[seq(2,length(unlist(MSECVtree)),2)])
AUCcv[4]<-mean(unlist(NBCV)[seq(2,length(unlist(NBCV)),2)])
AUCcv[5]<-mean(unlist(RFCV)[seq(2,length(unlist(RFCV)),2)])
AUCcv[6]<-mean(unlist(GBMCV)[seq(2,length(unlist(GBMCV)),2)])
AUCcv[7]<-mean(unlist(SVMCV)[seq(2,length(unlist(SVMCV)),2)])
AUCcv[8]<-mean(unlist(LASSOCV)[seq(2,length(unlist(LASSOCV)),2)])
#AUCcv[9]<-mean(unlist(RIDGECV)[seq(2,length(unlist(RIDGECV)),2)])

AUC.POSORTOWANE<-METODY[order(AUCcv,decreasing=T)]
MSE.POSORTOWANE<-METODY[order(MSEcv,decreasing=T)]


glmbic_CV <- data.frame(rep("glmBIC", length(OPICGLMCV)), unlist(OPICGLMCV)[seq(1,length(unlist(OPICGLMCV)),2)])
colnames(glmbic_CV) <- c("metoda", "blad")
glm_CV <- data.frame(rep("GLM", length(GLMCV)),unlist(GLMCV)[seq(1,length(unlist(GLMCV)),2)])
colnames(glm_CV) <- c("metoda", "blad")
DRZEWO_CV <- data.frame(rep("DRZEWO", length(MSECVtree)), unlist(MSECVtree)[seq(1,length(unlist(MSECVtree)),2)])
colnames(DRZEWO_CV) <- c("metoda", "blad")
NB_CV <- data.frame(rep("NB", length(NBCV)), unlist(NBCV)[seq(1,length(unlist(NBCV)),2)])
colnames(NB_CV) <- c("metoda", "blad")
RF_CV <- data.frame(rep("RF", length(RFCV)), unlist(RFCV)[seq(1,length(unlist(RFCV)),2)])
colnames(RF_CV) <- c("metoda", "blad")
GBM_CV <- data.frame(rep("GBM", length(GBMCV)), unlist(GBMCV)[seq(1,length(unlist(GBMCV)),2)])
colnames(GBM_CV) <- c("metoda", "blad")
SVM_CV <- data.frame(rep("svm",length(SVMCV)),unlist(SVMCV)[seq(1,length(unlist(SVMCV)),2)])
colnames(SVM_CV) <- c("metoda", "blad")
LASSO_CV <- data.frame(rep("LASSO", length(LASSOCV)), unlist(LASSOCV)[seq(1,length(unlist(LASSOCV)),2)])
colnames(LASSO_CV) <- c("metoda", "blad")
#RIDGE_CV <- data.frame(rep("RIDGE",length(RIDGECV)),unlist(RIDGECV)[seq(1,length(unlist(RIDGECV)),2)])
#colnames(RIDGE_CV) <- c("metoda", "blad")
bledycv <- rbind(GBM_CV,glmbic_CV,glm_CV,LASSO_CV,SVM_CV,DRZEWO_CV,RF_CV,NB_CV)

ggplot(bledycv, aes(x = metoda, y = blad, fill = metoda)) + geom_violin() + guides(fill = FALSE) +
  ggtitle("rozkład MSE cv dla różnych modeli") + stat_summary(fun.y = "mean", geom = "point", size = 4) 

glmbic_CV <- data.frame(rep("glmBIC", length(OPICGLMCV)), unlist(OPICGLMCV)[seq(2,length(unlist(OPICGLMCV)),2)])
colnames(glmbic_CV) <- c("metoda", "AUC")
glm_CV <- data.frame(rep("GLM", length(GLMCV)),unlist(GLMCV)[seq(2,length(unlist(GLMCV)),2)])
colnames(glm_CV) <- c("metoda", "AUC")
DRZEWO_CV <- data.frame(rep("DRZEWO", length(MSECVtree)), unlist(MSECVtree)[seq(2,length(unlist(MSECVtree)),2)])
colnames(DRZEWO_CV) <- c("metoda", "AUC")
NB_CV <- data.frame(rep("NB", length(NBCV)), unlist(NBCV)[seq(2,length(unlist(NBCV)),2)])
colnames(NB_CV) <- c("metoda", "AUC")
RF_CV <- data.frame(rep("RF", length(RFCV)), unlist(RFCV)[seq(2,length(unlist(RFCV)),2)])
colnames(RF_CV) <- c("metoda", "AUC")
GBM_CV <- data.frame(rep("GBM", length(GBMCV)), unlist(GBMCV)[seq(2,length(unlist(GBMCV)),2)])
colnames(GBM_CV) <- c("metoda", "AUC")
SVM_CV <- data.frame(rep("svm",length(SVMCV)),unlist(SVMCV)[seq(2,length(unlist(SVMCV)),2)])
colnames(SVM_CV) <- c("metoda", "AUC")
LASSO_CV <- data.frame(rep("LASSO", length(LASSOCV)), unlist(LASSOCV)[seq(2,length(unlist(LASSOCV)),2)])
colnames(LASSO_CV) <- c("metoda", "AUC")
#RIDGE_CV <- data.frame(rep("RIDGE",length(RIDGECV)),unlist(RIDGECV)[seq(2,length(unlist(RIDGECV)),2)])
#colnames(RIDGE_CV) <- c("metoda", "AUC")
bledycv <- rbind(LASSO_CV,RF_CV,DRZEWO_CV,glm_CV,NB_CV ,glmbic_CV,SVM_CV,GBM_CV)

ggplot(bledycv, aes(x = metoda, y = AUC, fill = metoda)) + geom_violin() + guides(fill = FALSE) +
  ggtitle("rozkład AUC cv dla różnych modeli") + stat_summary(fun.y = "mean", geom = "point", size = 4) 
```



#Model stacking
```{r,warning=FALSE,message=FALSE, results="hide",eval=FALSE}
#Stacking na final
dane<-geny
for(i in 5:(ncol(dane)-1)){
      dane[which(is.na(dane[,i])),i] <- mean(dane[,i], na.rm = TRUE)
}
ist<-istotne(dane[,-ncol(dane)],30)
dane<-dane[,c("age","death1y",ist,"smierc")]

dataset<-dane[,-ncol(dane)]
control <- trainControl(method="repeatedcv", number=10, repeats=5, savePredictions=T, classProbs=TRUE)
seed<-8
metric<-"Accuracy"
set.seed(8)
models <- caretList(as.factor(death1y)~., 
                    data=dataset, 
                    trControl=control,
                    tuneList = list(gbm=caretModelSpec(method='gbm', distribution="adaboost"), 
                                    glm=caretModelSpec(method='glm', family="binomial"),
                                    glmStepAIC=caretModelSpec(method='glmStepAIC', family="binomial", trace=FALSE, 
                                                              k=log(nrow(dataset))),
                                    glmnet=caretModelSpec(method='glmnet', family="binomial", preProcess=c("center","scale")
                                    ),
                                    rpart=caretModelSpec(method='rpart') ,
                                    rf=caretModelSpec(method='rf', ntree=25),
                                    nb=caretModelSpec(method='nb'),
                                    svmRadial=caretModelSpec(method='svmRadial',preProcess=c("center","scale")))) 
results <- resamples(models)

```

Poniżej znajduje się podsumowanie skuteczności naszych modeli oraz współczynnika kappa, który możemy interpretować jako częstość trafności klasyfikacji naszego modelu o którą przewyższa on trafność klasyfikacji modelu losowego, 0 oznacza model losowy, a 1 model idealny.

```{r, warning=FALSE,message=FALSE,}
load("~/resultdoprojektu.rda")
summary(results)[3]$statistics$Accuracy
dotplot(results)
```

Widzimy, że model Random Forest tworzy najskuteczniejszy model z accuracy do 75.37%. Glmnet,Naive Bayes oraz GBM posiadają podobny wynik, jednak dla nich współczynnik Kappa jest gorszy niż dla Random Forest. Reasumując modelami, które na postawie powyższej analizy okazują się być najlepsze , są: RF,GLMNET (lasso),NB. Aby wybrać modele, które chcemy ze sobą połączyć obliczmy macierz korelacji predykcji tych modeli. Gdy łączymy predykcje różnych modeli chcemy aby prognozy przedstawione przez te modele miały niska korelacje, ponieważ oznacza to, że modele są równie skuteczne ale na różne sposoby. Zatem dzięki temu nasz klasyfikator uczy się jak uzyskać najlepsze predykcje w celu udoskonalenia końcowego modelu.


```{r, warning=FALSE,message=FALSE,echo=FALSE,eval=FALSE,results="hide"}
set.seed(8)
models1 <- caretList(as.factor(death1y)~., 
                    data=as.data.frame(dataset), 
                    trControl=control,
                    tuneList = list(#gbm=caretModelSpec(method='gbm', distribution="adaboost"), 
                                    
                                    glmnet=caretModelSpec(method='glmnet', family="binomial", preProcess=c("center","scale")
                                    ),
                                    rf=caretModelSpec(method='rf', ntree=25),
                                    nb=caretModelSpec(method='nb')))
                                     
results1 <- resamples(models1)

```

```{r, warning=FALSE,message=FALSE}
load("~/results1doprojektu.rda")
modelCor(results1)
splom(results1)

```

Generalnie wszystkie pary predykcji są dosyć słabo skorelowane. Zatem ostateczny model stacking budujemy na podstawie tych trzech modeli. Widzimy, że nasz nowy model stacking utworzony metodą rf posiada skuteczność aż do 82%, co jest małym ulepszeniem modelu Radom Forest.

```{r, warning=FALSE,message=FALSE,eval=FALSE}
stackControl <- trainControl(method="repeatedcv", number=10, repeats=10, classProbs=TRUE)
set.seed(8)
stack.rf <- caretStack(models1, method="rf", metric=metric, trControl=stackControl)

set.seed(8)
stack.glm <- caretStack(models1, method="glm", metric=metric, trControl=stackControl)

```

```{r, warning=FALSE,message=FALSE}
load("~/stack.glm.rda")
load("~/stack.rf.rda")
print(stack.rf)
print(stack.glm)
```
#Predykcja na zbiorze final
```{r,message=FALSE,warning=FALSE,eval = FALSE}
final<-read.table(load("~/final.csv",sep=",", dec=".", header=TRUE)
final<-as.data.frame(final)

```

```{r,message=FALSE,warning=FALSE,eval = FALSE}
load("~/final.rda")
final1<-final[,c("age",ist)]
for(i in 2:ncol(final1)){
      final1[which(is.na(final1[,i])),i] <- mean(final1[,i], na.rm=TRUE)
}

pred<-predict(stack.rf,newdata = final1)
pred<-ifelse(pred=="alive",1,0)	
    
results<-as.data.frame(as.factor(pred))   
results<-cbind(c(1:250),results)    
rownames(results) <- NULL
names(results)[1]<-paste("rowid")
names(results)[2]<-paste("Expected")

write.table(results, file="resultsstacking1.csv", 
            sep = ",", dec = ".", row.names = FALSE)
```
